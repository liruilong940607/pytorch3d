{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import logging\n",
    "import math\n",
    "from os import path\n",
    "\n",
    "import imageio\n",
    "import torch\n",
    "from pytorch3d.renderer.points.pulsar import Renderer\n",
    "\n",
    "x, y = 650, 300"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.manual_seed(1)\n",
    "n_points = 10\n",
    "width = 1_000\n",
    "height = 1_000\n",
    "device = torch.device(\"cuda\")\n",
    "# The PyTorch3D system is right handed; in pulsar you can choose the handedness.\n",
    "# For easy reproducibility we use a right handed coordinate system here.\n",
    "renderer = Renderer(width, height, n_points, right_handed_system=True).to(device)\n",
    "# Generate sample data.\n",
    "vert_pos = torch.rand(n_points, 3, dtype=torch.float32, device=device) * 10.0\n",
    "vert_pos[:, 2] += 25.0\n",
    "vert_pos[:, :2] -= 5.0\n",
    "vert_col = torch.rand(n_points, 3, dtype=torch.float32, device=device, requires_grad=True)\n",
    "vert_rad = torch.rand(n_points, dtype=torch.float32, device=device)\n",
    "opacity = torch.ones_like(vert_rad) * 0.1\n",
    "opacity.requires_grad = True\n",
    "cam_params = torch.tensor(\n",
    "    [\n",
    "        0.0,\n",
    "        0.0,\n",
    "        0.0,  # Position 0, 0, 0 (x, y, z).\n",
    "        0.0,\n",
    "        math.pi,  # Because of the right handed system, the camera must look 'back'.\n",
    "        0.0,  # Rotation 0, 0, 0 (in axis-angle format).\n",
    "        5.0,  # Focal length in world size.\n",
    "        2.0,  # Sensor size in world size (width).\n",
    "    ],\n",
    "    dtype=torch.float32,\n",
    "    device=device,\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "\n",
    "vert_col.grad = None\n",
    "opacity.grad = None\n",
    "\n",
    "# Render.\n",
    "image = renderer(\n",
    "    vert_pos,\n",
    "    vert_col,\n",
    "    vert_rad,\n",
    "    cam_params,\n",
    "    1.0e-1,  # Renderer blending parameter gamma, in [1., 1e-5].\n",
    "    45.0,  # Maximum depth.\n",
    "    opacity=opacity,\n",
    "    mode=2,\n",
    ")\n",
    "print (y, x, image[y, x])\n",
    "image[y, x].sum().backward()\n",
    "print (vert_col.grad)\n",
    "print (opacity.grad)\n",
    "\n",
    "image = (image.cpu().detach() * 255.0).to(torch.uint8).numpy()\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from pytorch3d.transforms import axis_angle_to_matrix\n",
    "cam_pos = cam_params[0:3]\n",
    "cam_R = axis_angle_to_matrix(cam_params[3:6])\n",
    "cam_focal = cam_params[6] / cam_params[7] * width\n",
    "print (\"cam_pos:\", cam_pos)\n",
    "print (\"cam_R:\", cam_R)\n",
    "print (\"cam_focal:\", cam_focal)\n",
    "\n",
    "cam_T = - torch.matmul(cam_R, cam_pos)\n",
    "camtoworld = torch.cat([cam_R.t(), -cam_T[:, None]], dim=1)\n",
    "camtoworld = torch.cat([\n",
    "    camtoworld, torch.tensor([[0., 0., 0., 1.]], device=camtoworld.device)\n",
    "], dim=0)\n",
    "print (\"camtoworld\", camtoworld.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "\n",
    "Rays = collections.namedtuple(\"Rays\", (\"origins\", \"directions\", \"viewdirs\"))\n",
    "\n",
    "\n",
    "def generate_rays(w, h, focal, camtoworlds):\n",
    "    \"\"\"\n",
    "    Generate perspective camera rays. Principal point is at center.\n",
    "    Args:\n",
    "        w: int image width\n",
    "        h: int image heigth\n",
    "        focal: float real focal length\n",
    "        camtoworlds: jnp.ndarray [B, 4, 4] c2w homogeneous poses\n",
    "        equirect: if true, generates spherical rays instead of pinhole\n",
    "    Returns:\n",
    "        rays: Rays a namedtuple(origins [B, 3], directions [B, 3], viewdirs [B, 3])\n",
    "    \"\"\"\n",
    "    x, y = np.meshgrid(  # pylint: disable=unbalanced-tuple-unpacking\n",
    "        np.arange(w, dtype=np.float32),  # X-Axis (columns)\n",
    "        np.arange(h, dtype=np.float32),  # Y-Axis (rows)\n",
    "        indexing=\"xy\",\n",
    "    )\n",
    "\n",
    "    camera_dirs = np.stack(\n",
    "        [\n",
    "            (x + 0.5 - w * 0.5) / focal,\n",
    "            -(y + 0.5 - h * 0.5) / focal,\n",
    "            -np.ones_like(x),\n",
    "        ],\n",
    "        axis=-1,\n",
    "    )\n",
    "\n",
    "    c2w = camtoworlds[:, None, None, :3, :3]\n",
    "    camera_dirs = camera_dirs[None, Ellipsis, None]\n",
    "    directions = np.matmul(c2w, camera_dirs)[Ellipsis, 0]\n",
    "    origins = np.broadcast_to(\n",
    "        camtoworlds[:, None, None, :3, -1], directions.shape\n",
    "    )\n",
    "    norms = np.linalg.norm(directions, axis=-1, keepdims=True)\n",
    "    viewdirs = directions / norms\n",
    "    rays = Rays(\n",
    "        origins=origins, directions=directions, viewdirs=viewdirs\n",
    "    )\n",
    "    return rays\n",
    "\n",
    "\n",
    "rays = generate_rays(width, height, cam_focal.cpu(), camtoworld[None, :].cpu().numpy()) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def ray_sphere_intersections(rays, vert_pos, vert_rad):\n",
    "    # rays.origins, rays.viewdirs: [1, 500, 500, 3]\n",
    "    # vert_pos: [N, 3]\n",
    "    # vert_rad: [N, ]\n",
    "    vert_pos = vert_pos.cpu().numpy()\n",
    "    vert_rad = vert_rad.cpu().numpy()\n",
    "\n",
    "    # [N, 500, 500, 3]\n",
    "    o__sphere_ = vert_pos[:, None, None, :] - rays.origins\n",
    "    # [N, 500, 500]\n",
    "    o__p1_dist = np.sum(o__sphere_ * rays.viewdirs, axis=-1)\n",
    "    # [N, 500, 500, 3]\n",
    "    o__p1_ = rays.viewdirs * o__p1_dist[..., None]\n",
    "    # [N, 500, 500, 3]\n",
    "    p1__sphere_= o__sphere_ - o__p1_\n",
    "    # [N, 500, 500]\n",
    "    p1__sphere_dist = np.linalg.norm(p1__sphere_, axis=-1)\n",
    "    \n",
    "    # whether intersection happens\n",
    "    hits = np.logical_and(\n",
    "        o__p1_dist > 0, p1__sphere_dist <= vert_rad[:, None, None]\n",
    "    )\n",
    "    print (\"center:\", o__sphere_[:, y, x])\n",
    "    print (\"o__p1:\", o__p1_dist[:, y, x])\n",
    "    hits_depth = o__p1_dist\n",
    "    return hits, hits_depth \n",
    "\n",
    "hits, hits_depth = ray_sphere_intersections(rays, vert_pos, vert_rad)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "hits_depth[~hits] = float(\"inf\")\n",
    "mask = np.float32(hits_depth).min(axis=0)\n",
    "plt.imshow(mask)\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "vert_col.grad = None\n",
    "opacity.grad = None\n",
    "\n",
    "sorted_sphere_idxs = np.argsort(hits_depth[:, y, x], axis=0)\n",
    "\n",
    "bg_col = torch.ones((3,), device=device)\n",
    "light_intensity = 1.0\n",
    "color = torch.zeros((3,), device=device)\n",
    "for i, sphere_id in enumerate(sorted_sphere_idxs):\n",
    "    hit = hits[sphere_id, y, x]\n",
    "    t = hits_depth[sphere_id, y, x]\n",
    "    if t == float(\"inf\") or hit == False:\n",
    "        continue\n",
    "    if i < len(sorted_sphere_idxs) - 1:\n",
    "        sphere_id_next = sorted_sphere_idxs[i + 1]\n",
    "        t_next = hits_depth[sphere_id_next, y, x]\n",
    "    else:\n",
    "        t_next = float(\"inf\")\n",
    "    delta_t = min(abs(t_next - t), 1e10)\n",
    "    sigma = opacity[sphere_id]\n",
    "    att = torch.exp(- delta_t * sigma)\n",
    "    weight = light_intensity * (1. - att)\n",
    "    color = color + weight * vert_col[sphere_id]\n",
    "\n",
    "    print (\n",
    "        \"render|nerf accum. i(%d), sphere_id(%d) t(%.5f), delta_t(%.5f) \"\n",
    "        \"sigma(%.5f), att(%.5f), alpha(%.5f), \"\n",
    "        \"T(%.5f), weight(%.5f), \"\n",
    "        \"result(%.5f, %.5f, %.5f), \"\n",
    "        \"col_ptr(%.5f, %.5f, %.5f) \\n\" % (\n",
    "            i, sphere_id, t, delta_t,\n",
    "            sigma, att, 1. - att,\n",
    "            light_intensity, weight,\n",
    "            color[0], color[1], color[2],\n",
    "            vert_col[sphere_id][0], vert_col[sphere_id][1], vert_col[sphere_id][2]\n",
    "        )\n",
    "    )\n",
    "    light_intensity = light_intensity * att\n",
    "\n",
    "color = color + light_intensity * bg_col\n",
    "\n",
    "color.sum().backward()\n",
    "print (\"backward|nerf color grad.\", vert_col.grad)\n",
    "print (\"backward|nerf opacity grad.\", opacity.grad)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('pytorch3d': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "interpreter": {
   "hash": "feade9249399e47d96dc558fb0f01e968abba83d57db32291f782036ea8beebb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}